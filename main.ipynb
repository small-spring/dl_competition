{"cells":[{"cell_type":"markdown","metadata":{},"source":["# パッケージ・パス"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":783,"status":"ok","timestamp":1716816175306,"user":{"displayName":"三富佑人","userId":"02381481834375845603"},"user_tz":-540},"id":"6MK4bTe6NbUx"},"outputs":[],"source":["# パスへの移動\n","import os\n","project_path = '/workspace/'\n","os.chdir(project_path)\n","\n","\n","# パッケージのロード\n","import torch\n","import hydra\n","from omegaconf import DictConfig\n","from torch.utils.data import DataLoader\n","import random\n","import numpy as np\n","from src.models.evflownet import EVFlowNet\n","from src.datasets import DatasetProvider\n","from enum import Enum, auto\n","from src.datasets import train_collate\n","from tqdm import tqdm\n","from pathlib import Path\n","from typing import Dict, Any\n","import os\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"executionInfo":{"elapsed":6803,"status":"ok","timestamp":1716816183753,"user":{"displayName":"三富佑人","userId":"02381481834375845603"},"user_tz":-540},"id":"hcZTkQcZYICb","outputId":"41156112-c8a8-4b50-e0de-ea307d2031f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: hydra-core in /home/ubuntu/.local/lib/python3.10/site-packages (1.3.2)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ubuntu/.local/lib/python3.10/site-packages (from hydra-core) (4.9.3)\n","Requirement already satisfied: omegaconf<2.4,>=2.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from hydra-core) (2.3.0)\n","Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.10/site-packages (from hydra-core) (24.0)\n","Requirement already satisfied: PyYAML>=5.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.1)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: hdf5plugin in /home/ubuntu/.local/lib/python3.10/site-packages (4.4.0)\n","Requirement already satisfied: h5py in /home/ubuntu/.local/lib/python3.10/site-packages (from hdf5plugin) (3.11.0)\n","Requirement already satisfied: numpy>=1.17.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from h5py->hdf5plugin) (1.26.4)\n","Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease         \n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease                   \n","Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Reading package lists... Done\n"]}],"source":["!pip install hydra-core --upgrade\n","!pip install hdf5plugin\n","!sudo apt-get update\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9427393,"status":"ok","timestamp":1716825748347,"user":{"displayName":"三富佑人","userId":"02381481834375845603"},"user_tz":-540},"id":"0KDGC846Pk7f","outputId":"af29170b-db2b-4fc2-c5e1-7d4f36bb4ab9"},"outputs":[],"source":["# %env HYDRA_FULL_ERROR=1\n","# !python /workspace/main.py"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset_path: data\n","seed: 42\n","num_epoch: 10\n","data_loader:\n","  common:\n","    num_voxel_bins: 15\n","  train:\n","    batch_size: 8\n","    shuffle: true\n","  test:\n","    batch_size: 1\n","    shuffle: false\n","train:\n","  no_batch_norm: false\n","  initial_learning_rate: 0.01\n","  weight_decay: 0.0001\n","  epochs: 10\n","\n"]}],"source":["# hydra用のyamlファイルを読んでargsにロードする。\n","\n","import os\n","from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n","from omegaconf import OmegaConf\n","\n","with initialize_config_dir(version_base=None, config_dir=\"/workspace/configs\"):\n","    args = compose(config_name=\"base\")\n","\n","print(OmegaConf.to_yaml(args))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# 関数の定義\n","class RepresentationType(Enum):\n","    VOXEL = auto()\n","    STEPAN = auto()\n","\n","def set_seed(seed):\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","\n","def compute_epe_error(pred_flow: torch.Tensor, gt_flow: torch.Tensor):\n","    '''\n","    end-point-error (ground truthと予測値の二乗誤差)を計算\n","    pred_flow: torch.Tensor, Shape: torch.Size([B, 2, 480, 640]) => 予測したオプティカルフローデータ\n","    gt_flow: torch.Tensor, Shape: torch.Size([B, 2, 480, 640]) => 正解のオプティカルフローデータ\n","    '''\n","    epe = torch.mean(torch.mean(torch.norm(pred_flow - gt_flow, p=2, dim=1), dim=(1, 2)), dim=0)\n","    return epe\n","\n","def save_optical_flow_to_npy(flow: torch.Tensor, file_name: str):\n","    '''\n","    optical flowをnpyファイルに保存\n","    flow: torch.Tensor, Shape: torch.Size([2, 480, 640]) => オプティカルフローデータ\n","    file_name: str => ファイル名\n","    '''\n","    np.save(f\"{file_name}.npy\", flow.cpu().numpy())\n"]},{"cell_type":"markdown","metadata":{},"source":["# データローダ"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["'\\ntrain data:\\n    Type of batch: Dict\\n    Key: seq_name, Type: list\\n    Key: event_volume, Type: torch.Tensor, Shape: torch.Size([Batch, 4, 480, 640]) => イベントデータのバッチ\\n    Key: flow_gt, Type: torch.Tensor, Shape: torch.Size([Batch, 2, 480, 640]) => オプティカルフローデータのバッチ\\n    Key: flow_gt_valid_mask, Type: torch.Tensor, Shape: torch.Size([Batch, 1, 480, 640]) => オプティカルフローデータのvalid. ベースラインでは使わない\\n\\ntest data:\\n    Type of batch: Dict\\n    Key: seq_name, Type: list\\n    Key: event_volume, Type: torch.Tensor, Shape: torch.Size([Batch, 4, 480, 640]) => イベントデータのバッチ\\n'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# モデルの保存ディレクトリの作成・データのロード。\n","\n","# Create the directory if it doesn't exist\n","if not os.path.exists('checkpoints'):\n","    os.makedirs('checkpoints')\n","\n","\n","set_seed(args.seed)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","'''\n","    ディレクトリ構造:\n","\n","    data\n","    ├─test\n","    |  ├─test_city\n","    |  |    ├─events_left\n","    |  |    |   ├─events.h5\n","    |  |    |   └─rectify_map.h5\n","    |  |    └─forward_timestamps.txt\n","    └─train\n","        ├─zurich_city_11_a\n","        |    ├─events_left\n","        |    |       ├─ events.h5\n","        |    |       └─ rectify_map.h5\n","        |    ├─ flow_forward\n","        |    |       ├─ 000134.png\n","        |    |       |.....\n","        |    └─ forward_timestamps.txt\n","        ├─zurich_city_11_b\n","        └─zurich_city_11_c\n","    '''\n","\n","\n","# ------------------\n","#    Dataloader\n","# ------------------\n","loader = DatasetProvider(\n","    dataset_path=Path(args.dataset_path),\n","    representation_type=RepresentationType.VOXEL,\n","    delta_t_ms=100,\n","    num_bins=4\n",")\n","train_set = loader.get_train_dataset()\n","test_set = loader.get_test_dataset()\n","collate_fn = train_collate\n","\n","\n","train_data = DataLoader(train_set,\n","                                batch_size=args.data_loader.train.batch_size,\n","                                shuffle=args.data_loader.train.shuffle,\n","                                collate_fn=collate_fn,\n","                                drop_last=False)\n","test_data = DataLoader(test_set,\n","                                batch_size=args.data_loader.test.batch_size,\n","                                shuffle=args.data_loader.test.shuffle,\n","                                collate_fn=collate_fn,\n","                                drop_last=False)\n","\n","'''\n","train data:\n","    Type of batch: Dict\n","    Key: seq_name, Type: list\n","    Key: event_volume, Type: torch.Tensor, Shape: torch.Size([Batch, 4, 480, 640]) => イベントデータのバッチ\n","    Key: flow_gt, Type: torch.Tensor, Shape: torch.Size([Batch, 2, 480, 640]) => オプティカルフローデータのバッチ\n","    Key: flow_gt_valid_mask, Type: torch.Tensor, Shape: torch.Size([Batch, 1, 480, 640]) => オプティカルフローデータのvalid. ベースラインでは使わない\n","\n","test data:\n","    Type of batch: Dict\n","    Key: seq_name, Type: list\n","    Key: event_volume, Type: torch.Tensor, Shape: torch.Size([Batch, 4, 480, 640]) => イベントデータのバッチ\n","'''"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def save_model(model):\n","    current_time = time.strftime(\"%Y%m%d%H%M%S\")\n","    model_path = f\"checkpoints/model_{current_time}.pth\"\n","    torch.save(model.state_dict(), model_path)\n","    print(f\"Model saved to {model_path}\")\n","\n","    # ------------------\n","    #   Start predicting ()\n","    # ------------------\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.eval()\n","    flow: torch.Tensor = torch.tensor([]).to(device)\n","    with torch.no_grad():\n","        print(\"start test\")\n","        for batch in tqdm(test_data):\n","            batch: Dict[str, Any]\n","            event_image = batch[\"event_volume\"].to(device)\n","            batch_flow = model(event_image) # [1, 2, 480, 640]\n","            flow = torch.cat((flow, batch_flow), dim=0)  # [N, 2, 480, 640]\n","        print(\"test done\")\n","    # ------------------\n","    #  save submission\n","    # ------------------\n","    file_name = \"submission\"\n","    save_optical_flow_to_npy(flow, file_name)\n","    print(\"Submission saved\")\n","\n","\n","    # ------------------\n","    #   Start predicting ()\n","    # ------------------\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.eval()\n","    flow: torch.Tensor = torch.tensor([]).to(device)\n","    with torch.no_grad():\n","        print(\"start test\")\n","        for batch in tqdm(test_data):\n","            batch: Dict[str, Any]\n","            event_image = batch[\"event_volume\"].to(device)\n","            batch_flow = model(event_image) # [1, 2, 480, 640]\n","            flow = torch.cat((flow, batch_flow), dim=0)  # [N, 2, 480, 640]\n","        print(\"test done\")\n","    # ------------------\n","    #  save submission\n","    # ------------------\n","    file_name = \"submission\"\n","    save_optical_flow_to_npy(flow, file_name)"]},{"cell_type":"markdown","metadata":{},"source":["# トレーニング関数"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# 学習率スケジューラー\n","from torch.optim import lr_scheduler\n","\n","def train_model(args, model, n_epoch=1):\n","    # ------------------\n","    #   optimizer\n","    # ------------------\n","    optimizer = torch.optim.Adam(model.parameters(), lr=args.train.initial_learning_rate, weight_decay=args.train.weight_decay)\n","    scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n","\n","    # ------------------\n","    #   Start training\n","    # ------------------\n","    model.train()\n","    for epoch in range(n_epoch):\n","        total_loss = 0\n","        print(\"on epoch: {}\".format(epoch+1))\n","        for i, batch in enumerate(tqdm(train_data)):\n","            batch: Dict[str, Any]\n","            event_image = batch[\"event_volume\"].to(device) # [B, 4, 480, 640]\n","            ground_truth_flow = batch[\"flow_gt\"].to(device) # [B, 2, 480, 640]\n","            flow = model(event_image) # [B, 2, 480, 640]\n","            loss: torch.Tensor = compute_epe_error(flow, ground_truth_flow)\n","            print(f\"batch {i} loss: {loss.item()}\")\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step(loss.item())\n","            print(f\"learining rate: {scheduler.get_last_lr()}\")\n","\n","            # new_lr = scheduler(i)\n","            # set_lr(new_lr, optimizer)\n","\n","            if loss < 2.5:\n","                torch.save(model.state_dict(), \"checkpoints/model_under2_5.pth\")\n","                print(\"tmp model saved!\")\n","\n","            total_loss += loss.item()\n","        average_loss = total_loss / len(train_data)\n","        print(f'Epoch {epoch+1}, Loss: {average_loss}')\n","        \n","        current_time = time.strftime(\"%Y%m%d%H%M%S\")\n","        model_path = f\"checkpoints/model_{current_time}.pth\"\n","        torch.save(model.state_dict(), model_path)\n","        print(f\"Model saved to {model_path}\")\n","\n","\n","    # ------------------\n","    #   Start predicting ()\n","    # ------------------\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.eval()\n","    flow: torch.Tensor = torch.tensor([]).to(device)\n","    with torch.no_grad():\n","        print(\"start test\")\n","        for batch in tqdm(test_data):\n","            batch: Dict[str, Any]\n","            event_image = batch[\"event_volume\"].to(device)\n","            batch_flow = model(event_image) # [1, 2, 480, 640]\n","            flow = torch.cat((flow, batch_flow), dim=0)  # [N, 2, 480, 640]\n","        print(\"test done\")\n","    # ------------------\n","    #  save submission\n","    # ------------------\n","    file_name = \"submission\"\n","    save_optical_flow_to_npy(flow, file_name)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def evaluate(model, file_name=\"submission\"):\n","    # ------------------\n","    #   Start predicting ()\n","    # ------------------\n","    model.load_state_dict(torch.load(\"checkpoints/model_tmp.pth\", map_location=device))\n","    model.eval()\n","    flow: torch.Tensor = torch.tensor([]).to(device)\n","    with torch.no_grad():\n","        print(\"start test\")\n","        for batch in tqdm(test_data):\n","            batch: Dict[str, Any]\n","            event_image = batch[\"event_volume\"].to(device)\n","            batch_flow = model(event_image) # [1, 2, 480, 640]\n","            flow = torch.cat((flow, batch_flow), dim=0)  # [N, 2, 480, 640]\n","        print(\"test done\")\n","    # ------------------\n","    #  save submission\n","    # ------------------\n","    save_optical_flow_to_npy(flow, file_name)"]},{"cell_type":"markdown","metadata":{},"source":["# 2d ver."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["on epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/252 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]},{"name":"stdout","output_type":"stream","text":["batch 0 loss: 2.882945358133317\n"]},{"name":"stderr","output_type":"stream","text":["/home/ubuntu/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 1/252 [00:07<31:34,  7.55s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 1 loss: 7.964097044271981\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 2/252 [00:14<30:51,  7.41s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 2 loss: 5.299360674265261\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 3/252 [00:22<30:35,  7.37s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 3 loss: 18.10494331275967\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 4/252 [00:28<29:25,  7.12s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.008]\n","batch 4 loss: 7.683758577316789\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 5/252 [00:36<29:49,  7.25s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 5 loss: 5.260834195917714\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 6/252 [00:42<28:47,  7.02s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 6 loss: 4.7421369699083895\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 7/252 [00:50<29:12,  7.15s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 7 loss: 4.086549839775708\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 8/252 [00:57<28:36,  7.04s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 8 loss: 4.373871901906492\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▎         | 9/252 [01:04<28:45,  7.10s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 9 loss: 4.448087942899019\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 10/252 [01:11<28:18,  7.02s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 10 loss: 4.840691375202018\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 11/252 [01:18<28:59,  7.22s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 11 loss: 3.6233074956258218\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▍         | 12/252 [01:25<28:26,  7.11s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 12 loss: 3.97656004346325\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 13/252 [01:33<28:30,  7.16s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 13 loss: 3.815441402317383\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 14/252 [01:39<27:55,  7.04s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 14 loss: 5.008849801620603\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 15/252 [01:46<27:54,  7.07s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 15 loss: 5.0285678544476085\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▋         | 16/252 [01:53<27:20,  6.95s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 16 loss: 4.287112455461329\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 17/252 [02:00<27:31,  7.03s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 17 loss: 5.7525008582231845\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 18/252 [02:07<27:20,  7.01s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 18 loss: 3.441233174903262\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 19/252 [02:15<27:28,  7.07s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 19 loss: 5.941102144350193\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 20/252 [02:22<27:14,  7.05s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 20 loss: 5.214999859514849\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 21/252 [02:29<27:21,  7.11s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 21 loss: 4.324956709439748\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▊         | 22/252 [02:36<26:53,  7.02s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 22 loss: 5.291048148924431\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▉         | 23/252 [02:43<27:00,  7.08s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 23 loss: 3.7651368571835664\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 24/252 [02:49<26:27,  6.96s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 24 loss: 4.02173058964218\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 25/252 [02:57<26:44,  7.07s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 25 loss: 3.751424651364447\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 26/252 [03:04<26:19,  6.99s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 26 loss: 3.535908383829792\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 27/252 [03:11<26:20,  7.02s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 27 loss: 3.05007380000103\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 28/252 [03:18<26:04,  6.98s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 28 loss: 3.194563767934338\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 29/252 [03:25<26:30,  7.13s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 29 loss: 3.4836632376888983\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 30/252 [03:32<25:55,  7.01s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 30 loss: 4.092746173262425\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 31/252 [03:39<26:15,  7.13s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 31 loss: 3.9485774616657414\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 32/252 [03:46<25:49,  7.04s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 32 loss: 4.602485172487317\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 33/252 [03:53<26:07,  7.16s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 33 loss: 4.399599901881779\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 34/252 [04:01<25:53,  7.13s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 34 loss: 2.7344665812853637\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 35/252 [04:08<25:53,  7.16s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 35 loss: 4.867302948284415\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 36/252 [04:15<25:45,  7.16s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 36 loss: 3.968220241412511\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▍        | 37/252 [04:22<25:58,  7.25s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 37 loss: 3.337376104296551\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▌        | 38/252 [04:29<25:36,  7.18s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 38 loss: 2.9499502803979327\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▌        | 39/252 [04:37<25:32,  7.19s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 39 loss: 5.094045655188147\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 40/252 [04:43<24:53,  7.05s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 40 loss: 5.597382717867227\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▋        | 41/252 [04:51<25:11,  7.16s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 41 loss: 4.969121593829987\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 42/252 [04:58<24:45,  7.07s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 42 loss: 8.669046646938838\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 43/252 [05:05<24:53,  7.15s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 43 loss: 10.950356627211642\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 44/252 [05:12<24:34,  7.09s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.008]\n","batch 44 loss: 5.047271486005005\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 45/252 [05:19<24:40,  7.15s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 45 loss: 5.260150967648322\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 46/252 [05:26<24:15,  7.07s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 46 loss: 6.425229026386621\n"]},{"name":"stderr","output_type":"stream","text":[" 19%|█▊        | 47/252 [05:34<24:32,  7.18s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 47 loss: 7.743779626559682\n"]},{"name":"stderr","output_type":"stream","text":[" 19%|█▉        | 48/252 [05:40<24:09,  7.10s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 48 loss: 8.07796806518954\n"]},{"name":"stderr","output_type":"stream","text":[" 19%|█▉        | 49/252 [05:48<24:26,  7.22s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 49 loss: 5.978456284844864\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 50/252 [05:55<24:15,  7.20s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 50 loss: 5.937716369099247\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 51/252 [06:02<24:11,  7.22s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 51 loss: 7.390540130913894\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██        | 52/252 [06:09<23:45,  7.13s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 52 loss: 4.479421294220755\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██        | 53/252 [06:17<23:55,  7.21s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 53 loss: 4.745053238498862\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██▏       | 54/252 [06:24<23:38,  7.16s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 54 loss: 4.91549917844251\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 55/252 [06:31<23:51,  7.27s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 55 loss: 3.3771392605664596\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 56/252 [06:38<23:15,  7.12s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 56 loss: 3.1500273137742285\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 57/252 [06:45<23:16,  7.16s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 57 loss: 4.073938788890281\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 58/252 [06:52<22:55,  7.09s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 58 loss: 4.934104400144292\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 59/252 [07:00<23:24,  7.28s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 59 loss: 3.9766089938090596\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 60/252 [07:07<23:00,  7.19s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 60 loss: 3.8342416098019743\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 61/252 [07:14<22:59,  7.22s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 61 loss: 3.9332272627098313\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▍       | 62/252 [07:21<22:35,  7.14s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 62 loss: 3.494400602743087\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 63/252 [07:28<22:32,  7.16s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 63 loss: 3.0731098612850234\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 64/252 [07:35<22:05,  7.05s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 64 loss: 3.527004496097154\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 65/252 [07:43<22:24,  7.19s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 65 loss: 4.266165506536865\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 66/252 [07:50<22:14,  7.17s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 66 loss: 3.6530586515278807\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 67/252 [07:57<22:09,  7.19s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 67 loss: 3.87804536443313\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 68/252 [08:04<21:58,  7.16s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 68 loss: 2.962055991475848\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 69/252 [08:11<21:56,  7.19s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 69 loss: 3.710680242689651\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 70/252 [08:18<21:21,  7.04s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 70 loss: 3.7192604096921063\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 71/252 [08:25<21:22,  7.09s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 71 loss: 6.718011441368278\n"]},{"name":"stderr","output_type":"stream","text":[" 29%|██▊       | 72/252 [08:32<21:14,  7.08s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 72 loss: 4.495234175958906\n"]},{"name":"stderr","output_type":"stream","text":[" 29%|██▉       | 73/252 [08:41<22:22,  7.50s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 73 loss: 4.067910314290202\n"]},{"name":"stderr","output_type":"stream","text":[" 29%|██▉       | 74/252 [08:49<22:32,  7.60s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 74 loss: 4.6269098067706755\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 75/252 [08:57<23:00,  7.80s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 75 loss: 3.6088794854328192\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 76/252 [09:05<22:45,  7.76s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 76 loss: 3.2106321681389014\n"]},{"name":"stderr","output_type":"stream","text":[" 31%|███       | 77/252 [09:14<23:56,  8.21s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 77 loss: 3.196798476080245\n"]},{"name":"stderr","output_type":"stream","text":[" 31%|███       | 78/252 [09:22<23:50,  8.22s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 78 loss: 3.7543044536014554\n"]},{"name":"stderr","output_type":"stream","text":[" 31%|███▏      | 79/252 [09:31<23:54,  8.29s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 79 loss: 3.396085302742821\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 80/252 [09:38<22:59,  8.02s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 80 loss: 3.1481996026339907\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 81/252 [09:46<22:52,  8.02s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 81 loss: 3.308911441148612\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 82/252 [09:54<22:24,  7.91s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 82 loss: 3.540777340672311\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 83/252 [10:02<22:38,  8.04s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 83 loss: 2.87831349869462\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 84/252 [10:09<21:50,  7.80s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 84 loss: 2.663063923258413\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▎      | 85/252 [10:18<22:18,  8.01s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 85 loss: 3.2195839699185864\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▍      | 86/252 [10:26<22:28,  8.12s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 86 loss: 3.4985140490441147\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▍      | 87/252 [10:34<22:29,  8.18s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 87 loss: 2.9128209585324187\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▍      | 88/252 [10:42<21:49,  7.98s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 88 loss: 3.1589237604917457\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▌      | 89/252 [10:50<21:37,  7.96s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 89 loss: 2.6419090076627962\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 90/252 [10:57<21:02,  7.79s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 90 loss: 2.997593692410375\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▌      | 91/252 [11:06<21:23,  7.97s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 91 loss: 2.972639736761937\n"]},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 92/252 [11:14<21:13,  7.96s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 92 loss: 2.743314632913511\n"]},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 93/252 [11:22<21:21,  8.06s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 93 loss: 3.4517148381122817\n"]},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 94/252 [11:30<20:59,  7.97s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 94 loss: 2.686612651161396\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 95/252 [11:38<20:54,  7.99s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 95 loss: 3.019150467968499\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 96/252 [11:45<20:22,  7.83s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 96 loss: 2.3688422025110456\n"]},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 97/252 [11:53<20:33,  7.96s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","tmp model saved!\n","batch 97 loss: 2.8719154911197293\n"]},{"name":"stderr","output_type":"stream","text":[" 39%|███▉      | 98/252 [12:01<19:56,  7.77s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 98 loss: 2.497013067622177\n"]},{"name":"stderr","output_type":"stream","text":[" 39%|███▉      | 99/252 [12:09<20:07,  7.89s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","tmp model saved!\n","batch 99 loss: 2.485855153764672\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|███▉      | 100/252 [12:16<19:46,  7.80s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","tmp model saved!\n","batch 100 loss: 3.125245763012146\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 101/252 [12:25<19:50,  7.88s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 101 loss: 3.806483623868172\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 102/252 [12:32<19:30,  7.81s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 102 loss: 3.0026772172335043\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 103/252 [12:40<19:36,  7.90s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 103 loss: 2.863824714157296\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████▏     | 104/252 [12:48<19:17,  7.82s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 104 loss: 3.2435815017218057\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 105/252 [12:56<19:16,  7.86s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 105 loss: 2.827616429327078\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 106/252 [13:03<18:50,  7.74s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 106 loss: 3.0333303765286637\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 107/252 [13:11<18:59,  7.86s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 107 loss: 3.0220516082544817\n"]},{"name":"stderr","output_type":"stream","text":[" 43%|████▎     | 108/252 [13:19<18:36,  7.75s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 108 loss: 2.832284098578761\n"]},{"name":"stderr","output_type":"stream","text":[" 43%|████▎     | 109/252 [13:27<18:43,  7.86s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 109 loss: 3.0104732742235565\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▎     | 110/252 [13:34<18:13,  7.70s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 110 loss: 3.4243480705394864\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▍     | 111/252 [13:43<18:26,  7.85s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 111 loss: 3.3144665396877215\n"]},{"name":"stderr","output_type":"stream","text":[" 44%|████▍     | 112/252 [13:50<18:04,  7.75s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 112 loss: 2.690398103862759\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▍     | 113/252 [13:58<18:09,  7.84s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 113 loss: 2.456297482322154\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▌     | 114/252 [14:06<17:57,  7.81s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","tmp model saved!\n","batch 114 loss: 3.6267661794991666\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▌     | 115/252 [14:14<18:08,  7.94s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 115 loss: 2.532274716996543\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▌     | 116/252 [14:22<17:38,  7.78s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 116 loss: 3.5066904433395227\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▋     | 117/252 [14:30<17:49,  7.92s/it]"]},{"name":"stdout","output_type":"stream","text":["learining rate: [0.01]\n","batch 117 loss: 4.0125882728811\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▋     | 117/252 [14:37<16:53,  7.50s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m EVFlowNet(args\u001b[38;5;241m.\u001b[39mtrain)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path_load, map_location\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m evaluate(model)\n","Cell \u001b[0;32mIn[8], line 28\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(args, model, n_epoch)\u001b[0m\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 28\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearining rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler\u001b[38;5;241m.\u001b[39mget_last_lr()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# new_lr = scheduler(i)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# set_lr(new_lr, optimizer)\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# model_path_loadのモデルをロード\n","model_path_load=\"/workspace/checkpoints/model_20240717025440.pth\"\n","model = EVFlowNet(args.train).to(device)\n","model.load_state_dict(torch.load(model_path_load, map_location=device))\n","train_model(args, model)\n","\n","evaluate(model)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# 学習率スケジューラー\n","from torch.optim import lr_scheduler\n","\n","def train_model(args, model, n_epoch=1):\n","    # ------------------\n","    #   optimizer\n","    # ------------------\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=args.train.weight_decay)\n","\n","    # ------------------\n","    #   Start training\n","    # ------------------\n","    model.train()\n","    for epoch in range(n_epoch):\n","        total_loss = 0\n","        print(\"on epoch: {}\".format(epoch+1))\n","        for i, batch in enumerate(tqdm(train_data)):\n","            batch: Dict[str, Any]\n","            event_image = batch[\"event_volume\"].to(device) # [B, 4, 480, 640]\n","            ground_truth_flow = batch[\"flow_gt\"].to(device) # [B, 2, 480, 640]\n","            flow = model(event_image) # [B, 2, 480, 640]\n","            loss: torch.Tensor = compute_epe_error(flow, ground_truth_flow)\n","            print(f\"batch {i} loss: {loss.item()}\")\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","\n","            # new_lr = scheduler(i)\n","            # set_lr(new_lr, optimizer)\n","\n","            if loss < 2.3:\n","                current_time = time.strftime(\"%Y%m%d%H%M%S\")\n","                torch.save(model.state_dict(), f\"checkpoints/model_tmp_{current_time}.pth\")\n","                print(\"tmp model saved!\")\n","\n","            total_loss += loss.item()\n","        average_loss = total_loss / len(train_data)\n","        print(f'Epoch {epoch+1}, Loss: {average_loss}')\n","        \n","        current_time = time.strftime(\"%Y%m%d%H%M%S\")\n","        model_path = f\"checkpoints/model_{current_time}.pth\"\n","        torch.save(model.state_dict(), model_path)\n","        print(f\"Model saved to {model_path}\")\n","\n","\n","    # ------------------\n","    #   Start predicting ()\n","    # ------------------\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.eval()\n","    flow: torch.Tensor = torch.tensor([]).to(device)\n","    with torch.no_grad():\n","        print(\"start test\")\n","        for batch in tqdm(test_data):\n","            batch: Dict[str, Any]\n","            event_image = batch[\"event_volume\"].to(device)\n","            batch_flow = model(event_image) # [1, 2, 480, 640]\n","            flow = torch.cat((flow, batch_flow), dim=0)  # [N, 2, 480, 640]\n","        print(\"test done\")\n","    # ------------------\n","    #  save submission\n","    # ------------------\n","    file_name = \"submission\"\n","    save_optical_flow_to_npy(flow, file_name)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["start test\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/97 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","100%|██████████| 97/97 [00:09<00:00, 10.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["test done\n"]}],"source":["evaluate(model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["on epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/252 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["batch 0 loss: 3.841246244727871\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 1/252 [00:08<34:07,  8.16s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 1 loss: 3.2783570480625484\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 2/252 [00:16<34:46,  8.35s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 2 loss: 2.756024718486039\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 3/252 [00:24<33:06,  7.98s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 3 loss: 3.042670696728262\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 4/252 [00:31<31:56,  7.73s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 4 loss: 3.1549487278275627\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 5/252 [00:39<31:29,  7.65s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 5 loss: 3.102080711684323\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 6/252 [00:46<31:07,  7.59s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 6 loss: 3.4198335031421827\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 7/252 [00:54<31:02,  7.60s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 7 loss: 2.492196407364289\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 8/252 [01:01<30:46,  7.57s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 8 loss: 2.5631867079165738\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▎         | 9/252 [01:09<30:37,  7.56s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 9 loss: 3.0970622424020373\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 10/252 [01:16<30:33,  7.58s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 10 loss: 3.78546129270989\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 11/252 [01:24<31:10,  7.76s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 11 loss: 2.4223092064893144\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▍         | 12/252 [01:33<31:35,  7.90s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 12 loss: 2.6848495692542222\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 13/252 [01:40<30:59,  7.78s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 13 loss: 2.565180346791974\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 14/252 [01:48<30:38,  7.72s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 14 loss: 2.822029143679829\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 15/252 [01:55<30:17,  7.67s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 15 loss: 2.8342761820523905\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▋         | 16/252 [02:03<30:03,  7.64s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 16 loss: 2.9553209782934706\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 17/252 [02:11<30:21,  7.75s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 17 loss: 2.8302427128149823\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 18/252 [02:19<30:09,  7.73s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 18 loss: 2.5221174348862347\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 19/252 [02:26<30:11,  7.78s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 19 loss: 2.4060743477707485\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 20/252 [02:34<29:52,  7.73s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 20 loss: 2.764015071058996\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 21/252 [02:42<29:25,  7.64s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 21 loss: 2.5532110334102085\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▊         | 22/252 [02:49<29:14,  7.63s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 22 loss: 2.7621452364658987\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▉         | 23/252 [02:57<29:05,  7.62s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 23 loss: 2.5010559273926485\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 24/252 [03:04<28:47,  7.58s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 24 loss: 2.6034595231529045\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 25/252 [03:12<28:38,  7.57s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 25 loss: 2.4226811413212253\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 26/252 [03:19<28:12,  7.49s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 26 loss: 2.7851587019661768\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 27/252 [03:27<28:38,  7.64s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 27 loss: 4.922676707315945\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 28/252 [03:35<29:24,  7.88s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 28 loss: 2.2991096445634875\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 29/252 [03:44<29:43,  8.00s/it]"]},{"name":"stdout","output_type":"stream","text":["tmp model saved!\n","batch 29 loss: 3.3721811148963434\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 30/252 [03:52<29:49,  8.06s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 30 loss: 2.650776119806694\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 31/252 [04:00<29:42,  8.06s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 31 loss: 3.424701440263794\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 32/252 [04:08<29:46,  8.12s/it]"]},{"name":"stdout","output_type":"stream","text":["batch 32 loss: 2.521674920402023\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 33/252 [04:21<28:52,  7.91s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m EVFlowNet(args\u001b[38;5;241m.\u001b[39mtrain)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path_load, map_location\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m evaluate(model)\n","Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(args, model, n_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m flow \u001b[38;5;241m=\u001b[39m model(event_image) \u001b[38;5;66;03m# [B, 2, 480, 640]\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m compute_epe_error(flow, ground_truth_flow)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# model_path_loadのモデルをロード\n","model_path_load=\"/workspace/checkpoints/model_under2_5.pth\"\n","model = EVFlowNet(args.train).to(device)\n","model.load_state_dict(torch.load(model_path_load, map_location=device))\n","train_model(args, model)\n","\n","evaluate(model)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["on epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/252 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["batch 0 loss: 2.0533226726224836\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/252 [00:29<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m EVFlowNet(args\u001b[38;5;241m.\u001b[39mtrain)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path_load, map_location\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m evaluate(model)\n","Cell \u001b[0;32mIn[12], line 33\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(args, model, n_epoch)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# new_lr = scheduler(i)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# set_lr(new_lr, optimizer)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2.3\u001b[39m:\n\u001b[0;32m---> 33\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/model_under2_5.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmp model saved!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;66;03m# TODO: Change `*args` to `*` and remove the corresponding warning in docs when BC allows.\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;66;03m# Also remove the logic for arg parsing together.\u001b[39;00m\n\u001b[0;32m-> 1845\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstate_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, keep_vars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return a dictionary containing references to the whole state of the module.\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m \n\u001b[1;32m   1848\u001b[0m \u001b[38;5;124;03m    Both parameters and persistent buffers (e.g. running averages) are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1887\u001b[0m \n\u001b[1;32m   1888\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m     \u001b[38;5;66;03m# TODO: Remove `args` and the parsing logic when BC allows.\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# model_path_loadのモデルをロード\n","model_path_load=\"/workspace/checkpoints/model_under2_5.pth\"\n","model = EVFlowNet(args.train).to(device)\n","model.load_state_dict(torch.load(model_path_load, map_location=device))\n","train_model(args, model)\n","\n","evaluate(model)"]},{"cell_type":"markdown","metadata":{},"source":["# Mine version"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def sliding_window_collate(batch, window_size=2, step_size=1):\n","    # 初期化\n","    seq_names = []\n","    event_volumes = []\n","    flow_gts = []\n","    flow_gt_valid_masks = []\n","    \n","    # バッチの各要素に対して処理を行う\n","    for item in batch:\n","        seq_names.append(item['seq_name'])\n","        event_volumes.append(item['event_volume'])\n","        flow_gts.append(item['flow_gt'])\n","        flow_gt_valid_masks.append(item['flow_gt_valid_mask'])\n","    \n","    # スライディングウィンドウを適用する\n","    sliding_batches = []\n","    for i in range(0, len(event_volumes) - window_size + 1, step_size):\n","        sliding_batch = {\n","            'seq_name': seq_names[i:i + window_size],\n","            'event_volume': torch.stack(event_volumes[i:i + window_size]),\n","            'flow_gt': torch.stack(flow_gts[i:i + window_size]),\n","            'flow_gt_valid_mask': torch.stack(flow_gt_valid_masks[i:i + window_size]),\n","        }\n","        sliding_batches.append(sliding_batch)\n","    \n","    return sliding_batches\n","\n","# DataLoaderのcollate_fnを更新する\n","train_data = DataLoader(train_set,\n","                                batch_size=args.data_loader.train.batch_size,\n","                                shuffle=args.data_loader.train.shuffle,\n","                                collate_fn=lambda batch: sliding_window_collate(batch, window_size=2, step_size=1),\n","                                drop_last=False)\n","\n","test_data = DataLoader(test_set,\n","                                batch_size=args.data_loader.test.batch_size,\n","                                shuffle=args.data_loader.test.shuffle,\n","                                collate_fn=lambda batch: sliding_window_collate(batch, window_size=2, step_size=1),\n","                                drop_last=False)\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def slide_and_concatenate(images):\n","    # images: [batch_size, ch=4, width=480, height=640]\n","    batch_size, ch, width, height = images.shape\n","    \n","    # チャンネル数を2倍に増やすためのテンソル\n","    concatenated = torch.empty((batch_size - 1, ch * 2, width, height), dtype=images.dtype, device=images.device)\n","    \n","    for i in range(batch_size - 1):\n","        concatenated[i] = torch.cat((images[i], images[i + 1]), dim=0)\n","    \n","    return concatenated"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_my_model(args, model, n_epoch=1):\n","    # ------------------\n","    #   optimizer\n","    # ------------------\n","    optimizer = torch.optim.Adam(model.parameters(), lr=args.train.initial_learning_rate, weight_decay=args.train.weight_decay)\n","\n","    # ------------------\n","    #   Start training\n","    # ------------------\n","    model.train()\n","    for epoch in range(n_epoch):\n","        total_loss = 0\n","        print(\"on epoch: {}\".format(epoch+1))\n","        for i, batch in enumerate(tqdm(train_data)):\n","            batch: Dict[str, Any]\n","            event_image = batch[\"event_volume\"].to(device) # [B, 4, 480, 640]\n","            ground_truth_flow = batch[\"flow_gt\"].to(device) # [B, 2, 480, 640]\n","            flow = model(event_image) # [B, 2, 480, 640]\n","            loss: torch.Tensor = compute_epe_error(flow, ground_truth_flow)\n","            print(f\"batch {i} loss: {loss.item()}\")\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            if loss < 2.5:\n","                torch.save(model.state_dict(), \"checkpoints/model_tmp.pth\")\n","                print(\"tmp model saved!\")\n","\n","\n","            total_loss += loss.item()\n","        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_data)}')\n","        \n","        current_time = time.strftime(\"%Y%m%d%H%M%S\")\n","        model_path = f\"checkpoints/model_{current_time}.pth\"\n","        torch.save(model.state_dict(), model_path)\n","        print(f\"Model saved to {model_path}\")\n","\n","\n","    # ------------------\n","    #   Start predicting ()\n","    # ------------------\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.eval()\n","    flow: torch.Tensor = torch.tensor([]).to(device)\n","    with torch.no_grad():\n","        print(\"start test\")\n","        for batch in tqdm(test_data):\n","            batch: Dict[str, Any]\n","            event_image = batch[\"event_volume\"].to(device)\n","            batch_flow = model(event_image) # [1, 2, 480, 640]\n","            flow = torch.cat((flow, batch_flow), dim=0)  # [N, 2, 480, 640]\n","        print(\"test done\")\n","    # ------------------\n","    #  save submission\n","    # ------------------\n","    file_name = \"submission\"\n","    save_optical_flow_to_npy(flow, file_name)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["on epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/252 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","  0%|          | 0/252 [00:03<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m EVFlowNetMy(args\u001b[38;5;241m.\u001b[39mtrain)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path_load, map_location\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[9], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(args, model, n_epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m ground_truth_flow \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflow_gt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# [B, 2, 480, 640]\u001b[39;00m\n\u001b[1;32m     18\u001b[0m flow \u001b[38;5;241m=\u001b[39m model(event_image) \u001b[38;5;66;03m# [B, 2, 480, 640]\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m loss: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_epe_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_flow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mcompute_epe_error\u001b[0;34m(pred_flow, gt_flow)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_epe_error\u001b[39m(pred_flow: torch\u001b[38;5;241m.\u001b[39mTensor, gt_flow: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    end-point-error (ground truthと予測値の二乗誤差)を計算\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    pred_flow: torch.Tensor, Shape: torch.Size([B, 2, 480, 640]) => 予測したオプティカルフローデータ\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    gt_flow: torch.Tensor, Shape: torch.Size([B, 2, 480, 640]) => 正解のオプティカルフローデータ\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     epe \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mmean(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_flow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgt_flow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m epe\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/functional.py:1631\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1629\u001b[0m _p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m p\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\u001b[38;5;28minput\u001b[39m, _p, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from src.models.evflownet_my import EVFlowNetMy\n","from src.models.base import *\n","\n","# model_path_loadのモデルをロード\n","model_path_load=\"/workspace/checkpoints/model_20240717025440.pth\"\n","model = EVFlowNetMy(args.train).to(device)\n","model.load_state_dict(torch.load(model_path_load, map_location=device))\n","train_model(args, model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model saved to checkpoints/model_20240717052428.pth\n","start test\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/97 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","100%|██████████| 97/97 [00:12<00:00,  7.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["test done\n","Submission saved\n"]}],"source":["save_model(model)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOwK7NsK3TpYBxd1M/JLLAI","gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
